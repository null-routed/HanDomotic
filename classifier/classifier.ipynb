{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesture Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import json\n",
    "from scipy.stats import kurtosis, skew, iqr\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Create a list of DataFrames, one for each gesture\n",
    "    dfs = []        \n",
    "    for item in data:\n",
    "        df = pd.DataFrame({\n",
    "            'timestamps': item['timestamps'],\n",
    "            'xTimeSeries': item['xTimeSeries'],\n",
    "            'yTimeSeries': item['yTimeSeries'],\n",
    "            'zTimeSeries': item['zTimeSeries'],\n",
    "            'label': item['label']\n",
    "        })\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signal_bandpass(data, lowcut=5.0, highcut=25.0, fs=50, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', analog=True)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def extract_features(segment):\n",
    "    features = []\n",
    "    m_axis_data = []  # For M-axis calculation\n",
    "\n",
    "    for axis in ['xTimeSeries', 'yTimeSeries', 'zTimeSeries']:\n",
    "        axis_data = np.array(segment[axis])\n",
    "        m_axis_data.append(axis_data)\n",
    "        \n",
    "        # Time domain features\n",
    "        features += [\n",
    "            np.mean(axis_data),  # Mean\n",
    "            np.std(axis_data),   # Standard Deviation\n",
    "            np.ptp(axis_data),   # Peak to peak (range)\n",
    "            np.min(axis_data),   # Minimum\n",
    "            np.max(axis_data),   # Maximum\n",
    "            np.sum(np.abs(axis_data)) / len(axis_data),  # SMA (for this axis, later average across all axes)\n",
    "\n",
    "        ]\n",
    "\n",
    "        # Average absolute increment\n",
    "        avg_abs_increment = np.mean(np.abs(np.diff(axis_data)))\n",
    "        features.append(avg_abs_increment)\n",
    "\n",
    "        # Mean-crossings (a variant of zero-crossings focusing on mean level)\n",
    "        mean = np.mean(axis_data)\n",
    "        mean_crossings = np.sum(np.diff(axis_data - mean > 0).astype(int))\n",
    "        features.append(mean_crossings)\n",
    "\n",
    "        # Frequency domain features\n",
    "        features += extract_frequency_features(axis_data)\n",
    "\n",
    "    # Pairwise correlations\n",
    "    for i in range(3):\n",
    "        for j in range(i+1, 3):\n",
    "            correlation = np.corrcoef(m_axis_data[i], m_axis_data[j])[0, 1]\n",
    "            features.append(correlation)\n",
    "\n",
    "    return features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_frequency_features(data):\n",
    "    fft_vals = np.fft.rfft(data)  # Real FFT\n",
    "    spectral_energy = np.sum(np.abs(fft_vals)**2) / len(fft_vals)\n",
    "    freqs = np.fft.rfftfreq(len(data))\n",
    "    centroid = np.sum(freqs * np.abs(fft_vals)) / np.sum(np.abs(fft_vals))\n",
    "    return [spectral_energy, centroid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, labels):\n",
    "    model = make_pipeline(StandardScaler(), SVC(max_iter= 10000))\n",
    "    model.fit(features, labels)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_with_confidence(model, features, threshold = 1):\n",
    "    decision_values = model.decision_function([features])\n",
    "    prediction = model.predict([features])\n",
    "    confidence = np.abs(decision_values[0])  # Use absolute value for confidence\n",
    "    if confidence < threshold:\n",
    "        return \"Other\", confidence  # Return empty label if below threshold\n",
    "    else:\n",
    "        return prediction[0], confidence  # Return prediction and confidence otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_preprocessed_data(dataframes):\n",
    "    for i, df in enumerate(dataframes):\n",
    "        # Original data\n",
    "        if i < 3:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(df['timestamps'], df['xTimeSeries'], label='Original X', color='red')\n",
    "            plt.plot(df['timestamps'], df['yTimeSeries'], label='Original Y', color='green')\n",
    "            plt.plot(df['timestamps'], df['zTimeSeries'], label='Original Z', color='blue')\n",
    "            plt.title('Original Accelerometer Data')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Acceleration')\n",
    "            plt.legend()\n",
    "\n",
    "        # Preprocessed data\n",
    "        df['xTimeSeries'] = preprocess_signal_bandpass(df['xTimeSeries'])\n",
    "        df['yTimeSeries'] = preprocess_signal_bandpass(df['yTimeSeries'])\n",
    "        df['zTimeSeries'] = preprocess_signal_bandpass(df['zTimeSeries'])\n",
    "        if i < 3:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(df['timestamps'], df['xTimeSeries'], label='Preprocessed X', color='red')\n",
    "            plt.plot(df['timestamps'], df['yTimeSeries'], label='Preprocessed Y', color='green')\n",
    "            plt.plot(df['timestamps'], df['zTimeSeries'], label='Preprocessed Z', color='blue')\n",
    "            plt.title('Preprocessed Accelerometer Data')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Acceleration')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Practice Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Load gesture data\n",
    "\"\"\"\n",
    "dataframes = load_data('labeled_train_data/labeled_data_circle.json')  + load_data('labeled_train_data/labeled_data_clap.json')\n",
    "random_dataframes = load_data('labeled_train_data/labeled_data_random.json')\n",
    "\n",
    "# Plot preprocessed data for visual inspection (if preprocess is defined and required here)\n",
    "# plot_preprocessed_data(dataframes)\n",
    "\n",
    "# Prepare features and labels for gesture data\n",
    "\"\"\"\n",
    "features_file = json.loads(open('features.json', 'r').read())\n",
    "features = [f[\"features\"] for f in features_file if f[\"label\"] != \"Other\"]\n",
    "labels = [l[\"label\"] for l in features_file if l[\"label\"] != \"Other\"]\n",
    "\n",
    "# Split the gesture data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "# Prepare features and labels for random data, and use them only in the testing phase\n",
    "random_features = [f[\"features\"] for f in features_file if f[\"label\"] == \"Other\"]\n",
    "random_labels = [l[\"label\"] for l in features_file if l[\"label\"] == \"Other\"]\n",
    "\n",
    "features_test.extend(random_features)\n",
    "labels_test.extend(random_labels)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "model = train_classifier(features_train, labels_train)\n",
    "\n",
    "# Evaluate the classifier on the testing set (now includes random data)\n",
    "predictions_test = []\n",
    "confidences_test = []\n",
    "for feature in features_test:\n",
    "    prediction, confidence = predict_with_confidence(model, feature)\n",
    "    predictions_test.append(prediction)\n",
    "    confidences_test.append(confidence)\n",
    "\n",
    "for i, tup in enumerate(zip(predictions_test, labels_test)):\n",
    "    print(f\"Predicted: {tup[0]}, Actual: {tup[1]}, with confidence: {confidences_test[i]:.2f}\")\n",
    "\n",
    "# Calculate accuracy on the testing data including random data\n",
    "accuracy_test = sum(1 for p, l in zip(predictions_test, labels_test) if p == l) / len(labels_test)\n",
    "print(f\"Accuracy on test data including random movements: {accuracy_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming predictions_test and labels_test contain your predicted and true labels respectively\n",
    "cm = confusion_matrix(labels_test, predictions_test)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Identify unique label names and replace \"Other\" with \"No gesture\"\n",
    "unique_labels = np.unique(labels_test)\n",
    "unique_labels = [\"No gesture\" if label == \"Other\" else label for label in unique_labels]\n",
    "\n",
    "# Display the normalized confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=unique_labels)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f')\n",
    "plt.title(\"Confusion Matrix (in percentage)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "feature_count = len(features_train[0])  # Replace this with the actual number of features if known\n",
    "initial_type = [('float_input', FloatTensorType([None, feature_count]))]\n",
    "\n",
    "onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"gesture_classifier.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "def onnx_predict_with_confidence(onnx_model_path, features, threshold=1):\n",
    "    # Load the ONNX model\n",
    "    sess = rt.InferenceSession(onnx_model_path)\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    output_label = sess.get_outputs()[0].name  # The predicted label output\n",
    "    output_probability = sess.get_outputs()[1].name  # The probabilities output\n",
    "\n",
    "    # Run the model (ensure features is a numpy array and correctly shaped)\n",
    "    probabilities = sess.run([output_probability], {input_name: np.array([features], dtype=np.float32)})[0]\n",
    "    predictions = sess.run([output_label], {input_name: np.array([features], dtype=np.float32)})[0]\n",
    "    \n",
    "    # Calculate confidence (the highest class probability)\n",
    "    max_prob = np.max(probabilities)\n",
    "    prediction = predictions[0]\n",
    "\n",
    "    if max_prob < threshold:\n",
    "        return \"Other\", max_prob\n",
    "    else:\n",
    "        return prediction, max_prob\n",
    "\n",
    "# Example usage\n",
    "predictions_test = []\n",
    "confidences_test = []\n",
    "for feature in features_test:\n",
    "    prediction, confidence = onnx_predict_with_confidence(\"gesture_classifier.onnx\",feature)\n",
    "    predictions_test.append(prediction)\n",
    "    confidences_test.append(confidence)\n",
    "    \n",
    "conf_total = 0\n",
    "for i, tup in enumerate(zip(predictions_test, labels_test)):\n",
    "    print(f\"Predicted: {tup[0]}, Actual: {tup[1]}, with confidence: {confidences_test[i]:.2f}\")\n",
    "    conf_total += confidences_test[i]\n",
    "\n",
    "# Calculate accuracy on the testing data including random data\n",
    "accuracy_test = sum(1 for p, l in zip(predictions_test, labels_test) if p == l) / len(labels_test)\n",
    "avg_conf = conf_total / len(labels_test)\n",
    "print(f\"Accuracy on test data including random movements: {accuracy_test:.2f} and average confidence: {avg_conf:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
